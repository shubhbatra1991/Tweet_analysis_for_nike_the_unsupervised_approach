{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nnV3qVf4QxSK",
        "outputId": "e822cc7d-e93d-45da-a18b-9a6fd00a0275"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.3.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (1.19.5)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
            "Collecting pyspark\n",
            "  Downloading pyspark-3.2.1.tar.gz (281.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 281.4 MB 33 kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9.3\n",
            "  Downloading py4j-0.10.9.3-py2.py3-none-any.whl (198 kB)\n",
            "\u001b[K     |████████████████████████████████| 198 kB 23.1 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.2.1-py2.py3-none-any.whl size=281853642 sha256=3ef1faa0e073fdcf161087c9e25f1a0255e707cb1180351b8afb3c22185351f0\n",
            "  Stored in directory: /root/.cache/pip/wheels/9f/f5/07/7cd8017084dce4e93e84e92efd1e1d5334db05f2e83bcef74f\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9.3 pyspark-3.2.1\n"
          ]
        }
      ],
      "source": [
        "# Uncomment to install these libraries\n",
        "!pip install pandas\n",
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "mv3tekBNQ9k5"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col, isnan, when, count, size\n",
        "from pyspark.sql.types import ArrayType, StringType, IntegerType\n",
        "import pyspark.sql.functions as F\n",
        "\n",
        "from pyspark import SparkFiles\n",
        "\n",
        "from pprint import pprint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "7ZiJcE-MSKca"
      },
      "outputs": [],
      "source": [
        "spark = SparkSession.builder.appName(\"Tweet Analysis\").getOrCreate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EKx-f7ldSEIH"
      },
      "source": [
        "# Data Ingestion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fymI5gkSSFcC"
      },
      "outputs": [],
      "source": [
        "url = \"https://s3.amazonaws.com/peyck.es/BDA_Project/oct18-oct19.csv\"\n",
        "spark.sparkContext.addFile(url)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eAZejavA6F3k"
      },
      "outputs": [],
      "source": [
        "raw_df = spark.read.csv(\"file://\"+SparkFiles.get(\"oct18-oct19.csv\"), header=True, inferSchema= True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oIMdSHu6SbMN",
        "outputId": "66c8d910-6c01-4c35-c6f5-050d6678f897"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----------+---------------+---------------+-------+--------+---------+--------------------+----+--------------------+--------------------+--------+--------------------+\n",
            "|       date|       username|             to|replies|retweets|favorites|                text| geo|            mentions|            hashtags|      id|           permalink|\n",
            "+-----------+---------------+---------------+-------+--------+---------+--------------------+----+--------------------+--------------------+--------+--------------------+\n",
            "|4/1/19 0:00|  SneakerShouts|           null|      0|       2|       24|\"STEAL: Over 50% ...|null|                null|                null|1.11E+18|https://twitter.c...|\n",
            "|4/1/19 0:00|Ebay_Birmingham|           null|      0|       0|        0|Check out #Nike D...|null|               @eBay|#Nike #Nike #ebay...|1.11E+18|https://twitter.c...|\n",
            "|4/1/19 0:00|    SneakerNews|           null|      2|      15|      102|\"The Nike Air Max...|null|                null|                null|1.11E+18|https://twitter.c...|\n",
            "|4/1/19 0:00|     titoloshop|           null|      0|       0|        0|Nike Air Vapormax...|null|                null|                null|1.11E+18|https://twitter.c...|\n",
            "|4/1/19 0:00|   Taniabanks24|BornLiveDieFree|      2|       0|        0|@MichaelAvenatti ...|null|    @MichaelAvenatti|                null|1.11E+18|https://twitter.c...|\n",
            "|4/1/19 0:00|         bodega|           null|      0|       0|       11|Nike Moon Racer Q...|null|                null|#nike #footwear #...|1.11E+18|https://twitter.c...|\n",
            "|4/1/19 0:00|   mitasneakers|           null|      0|       0|        3|\"NIKE AIR VAPORMA...|null|                null|                null|1.11E+18|https://twitter.c...|\n",
            "|4/1/19 0:00|  CentervilleCF|           null|      0|       0|        2|Put the Nike Metc...|null|                null|                null|1.11E+18|https://twitter.c...|\n",
            "|4/1/19 0:01| BBNSportsKSCDJ|           null|      0|       0|        0|Time to buy Nike ...|null|                null|                null|1.11E+18|https://twitter.c...|\n",
            "|4/1/19 0:01|    SoleInsider|           null|      0|       0|        0|A Closer Look At ...|null|                null|                null|1.11E+18|https://twitter.c...|\n",
            "|4/1/19 0:01|     WendyCerne|  MollyJongFast|      0|       0|        1|Perfect time for ...|null|        @Kaepernick7|                null|1.11E+18|https://twitter.c...|\n",
            "|4/1/19 0:01|      robseize_|           null|      0|       0|        0|I‚Äôm trying to p...|null|                null|       #Nike #Adidas|1.11E+18|https://twitter.c...|\n",
            "|4/1/19 0:02| nexgenscouting|           null|      0|       3|        7|NEXGEN-NEW ENGLAN...|null|@Coach_NFT @hbour...|                null|1.11E+18|https://twitter.c...|\n",
            "|4/1/19 0:02|     snkr_twitr|           null|      0|       6|        7|30% off the Nike ...|null|                null|              #ADpic|1.11E+18|https://twitter.c...|\n",
            "|4/1/19 0:02|  JustMightLook|           null|      0|       0|        0|2007 AIR JORDAN 3...|null|                null|                null|1.11E+18|https://twitter.c...|\n",
            "|4/1/19 0:02|  JustMightLook|           null|      0|       0|        0|2017 NIKE AIR MAX...|null|                null|                null|1.11E+18|https://twitter.c...|\n",
            "|4/1/19 0:02|  JustMightLook|           null|      0|       0|        0|2018 AIR JORDAN 3...|null|                null|                null|1.11E+18|https://twitter.c...|\n",
            "|4/1/19 0:02|    breezeavery|           null|     19|       1|       97|okay hi i‚Äôm dec...|null|                null|                null|1.11E+18|https://twitter.c...|\n",
            "|4/1/19 0:02|     StockXLive|           null|      0|       2|        2|\"Lowest Ask: $104...|null|                null|  #nikebasketballpic|1.11E+18|https://twitter.c...|\n",
            "|4/1/19 0:02|   MrsSimone2u_|           null|      0|       0|        0|Check out what I'...|null|                null|                null|1.11E+18|https://twitter.c...|\n",
            "+-----------+---------------+---------------+-------+--------+---------+--------------------+----+--------------------+--------------------+--------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "raw_df.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ctLPI3BtUsVE"
      },
      "source": [
        "# Data Cleaning & Data Validation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gAjhZ55aUwOB"
      },
      "source": [
        "## Handling None Values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z_smG6crUI9n"
      },
      "outputs": [],
      "source": [
        "def check_for_nan(df, subset=None):\n",
        "    if subset:\n",
        "        df = df.select(subset)\n",
        "    for column in df.columns:\n",
        "        df = df.withColumn(column, df[\"`{}`\".format(column)].cast(\"string\"))\n",
        "    nan_df = df.select(\n",
        "        [\n",
        "            count(\n",
        "                when(\n",
        "                    col(c).contains(\"None\")\n",
        "                    | col(c).contains(\"NULL\")\n",
        "                    | col(c).contains(\"NaN\")\n",
        "                    | (col(c) == \"\")\n",
        "                    | col(c).isNull()\n",
        "                    | isnan(c),\n",
        "                    c,\n",
        "                )\n",
        "            ).alias(c)\n",
        "            for c in df.columns\n",
        "        ]\n",
        "    )\n",
        "    return nan_df.toPandas()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V6xloJCTU9tj"
      },
      "outputs": [],
      "source": [
        "nans_in_df = check_for_nan(raw_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G4knWF_mVkHC",
        "outputId": "8d2f21cd-bc3d-4fcb-937c-2d8fcbabeffe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total number of samples: 4430893\n"
          ]
        }
      ],
      "source": [
        "print(f\"Total number of samples: {raw_df.count()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "fWv_69uUT-cO",
        "outputId": "506b2086-8399-4b68-96fd-3715b0ae7ece"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-72facc37-2977-459e-b64b-a748eaff58ad\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>username</th>\n",
              "      <th>to</th>\n",
              "      <th>replies</th>\n",
              "      <th>retweets</th>\n",
              "      <th>favorites</th>\n",
              "      <th>text</th>\n",
              "      <th>geo</th>\n",
              "      <th>mentions</th>\n",
              "      <th>hashtags</th>\n",
              "      <th>id</th>\n",
              "      <th>permalink</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1307</td>\n",
              "      <td>2984222</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1274</td>\n",
              "      <td>4396600</td>\n",
              "      <td>3378046</td>\n",
              "      <td>3298391</td>\n",
              "      <td>24541</td>\n",
              "      <td>10273</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-72facc37-2977-459e-b64b-a748eaff58ad')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-72facc37-2977-459e-b64b-a748eaff58ad button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-72facc37-2977-459e-b64b-a748eaff58ad');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   date  username       to  replies  ...  mentions  hashtags     id  permalink\n",
              "0     0      1307  2984222        0  ...   3378046   3298391  24541      10273\n",
              "\n",
              "[1 rows x 12 columns]"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nans_in_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PAIgR0d9Vf5a"
      },
      "source": [
        "From a quick look, it seems:\n",
        "1. More than half of the \"to\" feature values are None.\n",
        "2. Almost all of the \"geo\" feature values are None.\n",
        "3. Most of the mentions and hashtags are None.\n",
        "\n",
        "From the above data, we can conclude that most users tweeting about Nike don't address the tweet to any single entity. They also don't include any geo location to their tweet. And they don't use mentions or hashtags when tweeting about Nike.\n",
        "\n",
        "**1. Because most of the values within geo feature are None, so we're going to drop \"geo\" from the dataframe.**\n",
        "\n",
        "**2. We cannot drop rows where feature \"to\", \"mentions\" & \"hashtags\" are None because a lot of samples are missing these values. We can replace None with empty string for \"to\", \"mentions\", \"hashtags\" later.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vDI7I-H9VHl3"
      },
      "outputs": [],
      "source": [
        "mostly_nan_features = 'geo'\n",
        "df = raw_df.drop(mostly_nan_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N1ygEb4UXGJ0",
        "outputId": "90bf76ea-66a2-4229-8329-1a79449c0aa0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----------+---------------+---------------+-------+--------+---------+--------------------+--------------------+--------------------+--------+--------------------+\n",
            "|       date|       username|             to|replies|retweets|favorites|                text|            mentions|            hashtags|      id|           permalink|\n",
            "+-----------+---------------+---------------+-------+--------+---------+--------------------+--------------------+--------------------+--------+--------------------+\n",
            "|4/1/19 0:00|  SneakerShouts|           null|      0|       2|       24|\"STEAL: Over 50% ...|                null|                null|1.11E+18|https://twitter.c...|\n",
            "|4/1/19 0:00|Ebay_Birmingham|           null|      0|       0|        0|Check out #Nike D...|               @eBay|#Nike #Nike #ebay...|1.11E+18|https://twitter.c...|\n",
            "|4/1/19 0:00|    SneakerNews|           null|      2|      15|      102|\"The Nike Air Max...|                null|                null|1.11E+18|https://twitter.c...|\n",
            "|4/1/19 0:00|     titoloshop|           null|      0|       0|        0|Nike Air Vapormax...|                null|                null|1.11E+18|https://twitter.c...|\n",
            "|4/1/19 0:00|   Taniabanks24|BornLiveDieFree|      2|       0|        0|@MichaelAvenatti ...|    @MichaelAvenatti|                null|1.11E+18|https://twitter.c...|\n",
            "|4/1/19 0:00|         bodega|           null|      0|       0|       11|Nike Moon Racer Q...|                null|#nike #footwear #...|1.11E+18|https://twitter.c...|\n",
            "|4/1/19 0:00|   mitasneakers|           null|      0|       0|        3|\"NIKE AIR VAPORMA...|                null|                null|1.11E+18|https://twitter.c...|\n",
            "|4/1/19 0:00|  CentervilleCF|           null|      0|       0|        2|Put the Nike Metc...|                null|                null|1.11E+18|https://twitter.c...|\n",
            "|4/1/19 0:01| BBNSportsKSCDJ|           null|      0|       0|        0|Time to buy Nike ...|                null|                null|1.11E+18|https://twitter.c...|\n",
            "|4/1/19 0:01|    SoleInsider|           null|      0|       0|        0|A Closer Look At ...|                null|                null|1.11E+18|https://twitter.c...|\n",
            "|4/1/19 0:01|     WendyCerne|  MollyJongFast|      0|       0|        1|Perfect time for ...|        @Kaepernick7|                null|1.11E+18|https://twitter.c...|\n",
            "|4/1/19 0:01|      robseize_|           null|      0|       0|        0|I‚Äôm trying to p...|                null|       #Nike #Adidas|1.11E+18|https://twitter.c...|\n",
            "|4/1/19 0:02| nexgenscouting|           null|      0|       3|        7|NEXGEN-NEW ENGLAN...|@Coach_NFT @hbour...|                null|1.11E+18|https://twitter.c...|\n",
            "|4/1/19 0:02|     snkr_twitr|           null|      0|       6|        7|30% off the Nike ...|                null|              #ADpic|1.11E+18|https://twitter.c...|\n",
            "|4/1/19 0:02|  JustMightLook|           null|      0|       0|        0|2007 AIR JORDAN 3...|                null|                null|1.11E+18|https://twitter.c...|\n",
            "|4/1/19 0:02|  JustMightLook|           null|      0|       0|        0|2017 NIKE AIR MAX...|                null|                null|1.11E+18|https://twitter.c...|\n",
            "|4/1/19 0:02|  JustMightLook|           null|      0|       0|        0|2018 AIR JORDAN 3...|                null|                null|1.11E+18|https://twitter.c...|\n",
            "|4/1/19 0:02|    breezeavery|           null|     19|       1|       97|okay hi i‚Äôm dec...|                null|                null|1.11E+18|https://twitter.c...|\n",
            "|4/1/19 0:02|     StockXLive|           null|      0|       2|        2|\"Lowest Ask: $104...|                null|  #nikebasketballpic|1.11E+18|https://twitter.c...|\n",
            "|4/1/19 0:02|   MrsSimone2u_|           null|      0|       0|        0|Check out what I'...|                null|                null|1.11E+18|https://twitter.c...|\n",
            "+-----------+---------------+---------------+-------+--------+---------+--------------------+--------------------+--------------------+--------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pyYBXyCMcQr1"
      },
      "outputs": [],
      "source": [
        "# Replacing None with empty string\n",
        "none_to_empty_string_features = ['to', 'mentions', 'hashtags']\n",
        "df = df.fillna('', subset=none_to_empty_string_features)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Q3spFyGZXo2"
      },
      "source": [
        "## Checking for Data Types"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NhW-K3f4X_pQ",
        "outputId": "23af0e0c-c477-4231-c70c-eae5a8b99f13"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'date': 'string',\n",
            " 'favorites': 'int',\n",
            " 'hashtags': 'string',\n",
            " 'id': 'string',\n",
            " 'mentions': 'string',\n",
            " 'permalink': 'string',\n",
            " 'replies': 'int',\n",
            " 'retweets': 'int',\n",
            " 'text': 'string',\n",
            " 'to': 'string',\n",
            " 'username': 'string'}\n"
          ]
        }
      ],
      "source": [
        "pprint(dict(df.dtypes))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "STDen1F8aJcm"
      },
      "source": [
        "As you can see, most of the features are either string or int. However, it doesn't make sense for the \"date\" feature to be string. We need to change \"date\" feature from string to date type.\n",
        "\n",
        "We also need to clean \"mentions\" and \"hashtags\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "okmSjoCeZmqq"
      },
      "outputs": [],
      "source": [
        "def convert_timestamp(df, timestamp_column, replace_original=True):\n",
        "    df_with_timestamp = df.withColumn(\n",
        "        \"timestamp\", F.to_timestamp(timestamp_column, \"M/d/yy H:mm\")\n",
        "    )\n",
        "\n",
        "    # Making sure timestamp conversion took place accurately without creating any new NaN values\n",
        "    nan_df = check_for_nan(df_with_timestamp, subset=[\"timestamp\"])\n",
        "    if nan_df[\"timestamp\"].values[0] > 0:\n",
        "        raise ValueError(\n",
        "            f\"Conversion of {timestamp_column} to type timestamp generated unexpected\"\n",
        "            f\"NaN values.\"\n",
        "        )\n",
        "\n",
        "    if replace_original:\n",
        "        df_with_timestamp = df_with_timestamp.drop(timestamp_column)\n",
        "        df_with_timestamp = df_with_timestamp.withColumnRenamed(\n",
        "            \"timestamp\", timestamp_column\n",
        "        )\n",
        "    return df_with_timestamp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qTPeNNlha290"
      },
      "outputs": [],
      "source": [
        "# Convert date to timestamp type\n",
        "df = convert_timestamp(df, \"date\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_wCNzZvda9KX"
      },
      "outputs": [],
      "source": [
        "def remove_empty_strings(list_of_strings):\n",
        "  return [string for string in list_of_strings if string]\n",
        "clean_list = F.udf(remove_empty_strings, ArrayType(StringType()))\n",
        "\n",
        "def break_into_list(df, feature, special_identifier):\n",
        "  df = df.withColumn(feature, clean_list(F.split(feature, special_identifier)))\n",
        "  return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4efvOj2DfZ75"
      },
      "outputs": [],
      "source": [
        "# Converting 'mentions' and 'hashtags' from string to list of string\n",
        "df = break_into_list(df, 'hashtags', '#')\n",
        "df = break_into_list(df, 'mentions', '@')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ubwXhRh4gLay",
        "outputId": "9d3999f7-4190-4749-8f0c-678e912269ab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---------------+---------------+-------+--------+---------+--------------------+--------------------+--------------------+--------+--------------------+-------------------+\n",
            "|       username|             to|replies|retweets|favorites|                text|            mentions|            hashtags|      id|           permalink|               date|\n",
            "+---------------+---------------+-------+--------+---------+--------------------+--------------------+--------------------+--------+--------------------+-------------------+\n",
            "|  SneakerShouts|               |      0|       2|       24|\"STEAL: Over 50% ...|                  []|                  []|1.11E+18|https://twitter.c...|2019-04-01 00:00:00|\n",
            "|Ebay_Birmingham|               |      0|       0|        0|Check out #Nike D...|              [eBay]|[Nike , Nike , eb...|1.11E+18|https://twitter.c...|2019-04-01 00:00:00|\n",
            "|    SneakerNews|               |      2|      15|      102|\"The Nike Air Max...|                  []|                  []|1.11E+18|https://twitter.c...|2019-04-01 00:00:00|\n",
            "|     titoloshop|               |      0|       0|        0|Nike Air Vapormax...|                  []|                  []|1.11E+18|https://twitter.c...|2019-04-01 00:00:00|\n",
            "|   Taniabanks24|BornLiveDieFree|      2|       0|        0|@MichaelAvenatti ...|   [MichaelAvenatti]|                  []|1.11E+18|https://twitter.c...|2019-04-01 00:00:00|\n",
            "|         bodega|               |      0|       0|       11|Nike Moon Racer Q...|                  []|[nike , footwear ...|1.11E+18|https://twitter.c...|2019-04-01 00:00:00|\n",
            "|   mitasneakers|               |      0|       0|        3|\"NIKE AIR VAPORMA...|                  []|                  []|1.11E+18|https://twitter.c...|2019-04-01 00:00:00|\n",
            "|  CentervilleCF|               |      0|       0|        2|Put the Nike Metc...|                  []|                  []|1.11E+18|https://twitter.c...|2019-04-01 00:00:00|\n",
            "| BBNSportsKSCDJ|               |      0|       0|        0|Time to buy Nike ...|                  []|                  []|1.11E+18|https://twitter.c...|2019-04-01 00:01:00|\n",
            "|    SoleInsider|               |      0|       0|        0|A Closer Look At ...|                  []|                  []|1.11E+18|https://twitter.c...|2019-04-01 00:01:00|\n",
            "|     WendyCerne|  MollyJongFast|      0|       0|        1|Perfect time for ...|       [Kaepernick7]|                  []|1.11E+18|https://twitter.c...|2019-04-01 00:01:00|\n",
            "|      robseize_|               |      0|       0|        0|I‚Äôm trying to p...|                  []|     [Nike , Adidas]|1.11E+18|https://twitter.c...|2019-04-01 00:01:00|\n",
            "| nexgenscouting|               |      0|       3|        7|NEXGEN-NEW ENGLAN...|[Coach_NFT , hbou...|                  []|1.11E+18|https://twitter.c...|2019-04-01 00:02:00|\n",
            "|     snkr_twitr|               |      0|       6|        7|30% off the Nike ...|                  []|             [ADpic]|1.11E+18|https://twitter.c...|2019-04-01 00:02:00|\n",
            "|  JustMightLook|               |      0|       0|        0|2007 AIR JORDAN 3...|                  []|                  []|1.11E+18|https://twitter.c...|2019-04-01 00:02:00|\n",
            "|  JustMightLook|               |      0|       0|        0|2017 NIKE AIR MAX...|                  []|                  []|1.11E+18|https://twitter.c...|2019-04-01 00:02:00|\n",
            "|  JustMightLook|               |      0|       0|        0|2018 AIR JORDAN 3...|                  []|                  []|1.11E+18|https://twitter.c...|2019-04-01 00:02:00|\n",
            "|    breezeavery|               |     19|       1|       97|okay hi i‚Äôm dec...|                  []|                  []|1.11E+18|https://twitter.c...|2019-04-01 00:02:00|\n",
            "|     StockXLive|               |      0|       2|        2|\"Lowest Ask: $104...|                  []| [nikebasketballpic]|1.11E+18|https://twitter.c...|2019-04-01 00:02:00|\n",
            "|   MrsSimone2u_|               |      0|       0|        0|Check out what I'...|                  []|                  []|1.11E+18|https://twitter.c...|2019-04-01 00:02:00|\n",
            "+---------------+---------------+-------+--------+---------+--------------------+--------------------+--------------------+--------+--------------------+-------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x9VAnajEfyMr",
        "outputId": "3515abf6-bb52-4c44-f557-fc142cf59dae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('username', 'string'),\n",
            " ('to', 'string'),\n",
            " ('replies', 'int'),\n",
            " ('retweets', 'int'),\n",
            " ('favorites', 'int'),\n",
            " ('text', 'string'),\n",
            " ('mentions', 'array<string>'),\n",
            " ('hashtags', 'array<string>'),\n",
            " ('id', 'string'),\n",
            " ('permalink', 'string'),\n",
            " ('date', 'timestamp')]\n"
          ]
        }
      ],
      "source": [
        "pprint(df.dtypes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i-jdVR0OgwfQ"
      },
      "source": [
        "We've succesfully changed the data types to data types more suitable for analysis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qI5_dU0fg9mc"
      },
      "source": [
        "## Dropping Unwanted Features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UTc1TD1bhBc4"
      },
      "source": [
        "There are some columns which are purely randomly assigned to a tweet and are of no significance to our analysis. We should drop these columns. These columns are:\n",
        "1. \"id\" feature: because ids are randomly assigned.\n",
        "2. \"permanlik\" feature: link to tweet doesn't affect the analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4fxDqqbBbKZV"
      },
      "outputs": [],
      "source": [
        "unwanted_features = (\"id\", \"permalink\")\n",
        "df = df.drop(*unwanted_features)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lLkOeCqZiY_J"
      },
      "source": [
        "# Data Pre-processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Ngo7rwRibiV"
      },
      "source": [
        "Our hypothesis was **\"Given a tweet, we can predict the number of engagements.\"** Let's prepare the dataset for the same."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5YXGbAgli01r"
      },
      "source": [
        "## Creating Labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TefrpO9Oi5Jk"
      },
      "source": [
        "We're predicting engagements. In our case engagement would be the sum of \"replies\", \"retweets & \"favourites\" features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Hum75H3iaq0"
      },
      "outputs": [],
      "source": [
        "df = df.withColumn(\"engagement\", F.col(\"replies\") + F.col(\"retweets\") + F.col(\"favorites\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NUaDBTQ7xW6m"
      },
      "outputs": [],
      "source": [
        "label_columns = ('replies', 'retweets', 'favorites')\n",
        "df = df.drop(*label_columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tn2mj9gTxjGU",
        "outputId": "2942dc78-29da-4566-eaec-ac2cea0dae5e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---------------+---------------+--------------------+--------------------+--------------------+-------------------+----------+\n",
            "|       username|             to|                text|            mentions|            hashtags|               date|engagement|\n",
            "+---------------+---------------+--------------------+--------------------+--------------------+-------------------+----------+\n",
            "|  SneakerShouts|               |\"STEAL: Over 50% ...|                  []|                  []|2019-04-01 00:00:00|        26|\n",
            "|Ebay_Birmingham|               |Check out #Nike D...|              [eBay]|[Nike , Nike , eb...|2019-04-01 00:00:00|         0|\n",
            "|    SneakerNews|               |\"The Nike Air Max...|                  []|                  []|2019-04-01 00:00:00|       119|\n",
            "|     titoloshop|               |Nike Air Vapormax...|                  []|                  []|2019-04-01 00:00:00|         0|\n",
            "|   Taniabanks24|BornLiveDieFree|@MichaelAvenatti ...|   [MichaelAvenatti]|                  []|2019-04-01 00:00:00|         2|\n",
            "|         bodega|               |Nike Moon Racer Q...|                  []|[nike , footwear ...|2019-04-01 00:00:00|        11|\n",
            "|   mitasneakers|               |\"NIKE AIR VAPORMA...|                  []|                  []|2019-04-01 00:00:00|         3|\n",
            "|  CentervilleCF|               |Put the Nike Metc...|                  []|                  []|2019-04-01 00:00:00|         2|\n",
            "| BBNSportsKSCDJ|               |Time to buy Nike ...|                  []|                  []|2019-04-01 00:01:00|         0|\n",
            "|    SoleInsider|               |A Closer Look At ...|                  []|                  []|2019-04-01 00:01:00|         0|\n",
            "|     WendyCerne|  MollyJongFast|Perfect time for ...|       [Kaepernick7]|                  []|2019-04-01 00:01:00|         1|\n",
            "|      robseize_|               |I‚Äôm trying to p...|                  []|     [Nike , Adidas]|2019-04-01 00:01:00|         0|\n",
            "| nexgenscouting|               |NEXGEN-NEW ENGLAN...|[Coach_NFT , hbou...|                  []|2019-04-01 00:02:00|        10|\n",
            "|     snkr_twitr|               |30% off the Nike ...|                  []|             [ADpic]|2019-04-01 00:02:00|        13|\n",
            "|  JustMightLook|               |2007 AIR JORDAN 3...|                  []|                  []|2019-04-01 00:02:00|         0|\n",
            "|  JustMightLook|               |2017 NIKE AIR MAX...|                  []|                  []|2019-04-01 00:02:00|         0|\n",
            "|  JustMightLook|               |2018 AIR JORDAN 3...|                  []|                  []|2019-04-01 00:02:00|         0|\n",
            "|    breezeavery|               |okay hi i‚Äôm dec...|                  []|                  []|2019-04-01 00:02:00|       117|\n",
            "|     StockXLive|               |\"Lowest Ask: $104...|                  []| [nikebasketballpic]|2019-04-01 00:02:00|         4|\n",
            "|   MrsSimone2u_|               |Check out what I'...|                  []|                  []|2019-04-01 00:02:00|         0|\n",
            "+---------------+---------------+--------------------+--------------------+--------------------+-------------------+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3mWFv_7S1hm4"
      },
      "source": [
        "## Building Features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltjnyP79BM-x"
      },
      "source": [
        "## Extracting Information From Hashtag"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z1ptUWjVBgNz"
      },
      "outputs": [],
      "source": [
        "df = df.withColumn('number_hashtags', size(F.col('hashtags')))\n",
        "\n",
        "# Since hashtags are already part of the main text. We can drop the actual hashtag.\n",
        "df = df.drop('hashtags')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CcFV1ROZGquG"
      },
      "source": [
        "## Extracting Information From Mentions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eVrwMxKIGvoS"
      },
      "outputs": [],
      "source": [
        "df = df.withColumn('number_mentions', size(F.col('mentions')))\n",
        "\n",
        "# Since hashtags are already part of the main text. We can drop the actual hashtag.\n",
        "df = df.drop('mentions')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qNklfPoZ6lzN",
        "outputId": "e0a67893-ae73-4a14-80ed-dcdc2124481a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---------------+---------------+--------------------+-------------------+----------+---------------+---------------+\n",
            "|       username|             to|                text|               date|engagement|number_hashtags|number_mentions|\n",
            "+---------------+---------------+--------------------+-------------------+----------+---------------+---------------+\n",
            "|  SneakerShouts|               |\"STEAL: Over 50% ...|2019-04-01 00:00:00|        26|              0|              0|\n",
            "|Ebay_Birmingham|               |Check out #Nike D...|2019-04-01 00:00:00|         0|              5|              1|\n",
            "|    SneakerNews|               |\"The Nike Air Max...|2019-04-01 00:00:00|       119|              0|              0|\n",
            "|     titoloshop|               |Nike Air Vapormax...|2019-04-01 00:00:00|         0|              0|              0|\n",
            "|   Taniabanks24|BornLiveDieFree|@MichaelAvenatti ...|2019-04-01 00:00:00|         2|              0|              1|\n",
            "|         bodega|               |Nike Moon Racer Q...|2019-04-01 00:00:00|        11|              3|              0|\n",
            "|   mitasneakers|               |\"NIKE AIR VAPORMA...|2019-04-01 00:00:00|         3|              0|              0|\n",
            "|  CentervilleCF|               |Put the Nike Metc...|2019-04-01 00:00:00|         2|              0|              0|\n",
            "| BBNSportsKSCDJ|               |Time to buy Nike ...|2019-04-01 00:01:00|         0|              0|              0|\n",
            "|    SoleInsider|               |A Closer Look At ...|2019-04-01 00:01:00|         0|              0|              0|\n",
            "|     WendyCerne|  MollyJongFast|Perfect time for ...|2019-04-01 00:01:00|         1|              0|              1|\n",
            "|      robseize_|               |I‚Äôm trying to p...|2019-04-01 00:01:00|         0|              2|              0|\n",
            "| nexgenscouting|               |NEXGEN-NEW ENGLAN...|2019-04-01 00:02:00|        10|              0|              4|\n",
            "|     snkr_twitr|               |30% off the Nike ...|2019-04-01 00:02:00|        13|              1|              0|\n",
            "|  JustMightLook|               |2007 AIR JORDAN 3...|2019-04-01 00:02:00|         0|              0|              0|\n",
            "|  JustMightLook|               |2017 NIKE AIR MAX...|2019-04-01 00:02:00|         0|              0|              0|\n",
            "|  JustMightLook|               |2018 AIR JORDAN 3...|2019-04-01 00:02:00|         0|              0|              0|\n",
            "|    breezeavery|               |okay hi i‚Äôm dec...|2019-04-01 00:02:00|       117|              0|              0|\n",
            "|     StockXLive|               |\"Lowest Ask: $104...|2019-04-01 00:02:00|         4|              1|              0|\n",
            "|   MrsSimone2u_|               |Check out what I'...|2019-04-01 00:02:00|         0|              0|              0|\n",
            "+---------------+---------------+--------------------+-------------------+----------+---------------+---------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CONt22mR1kqu"
      },
      "source": [
        "### Converting \"username\" & \"to\" feature to one-hot encoded feature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JrKGOrtQ1j5s"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml.feature import OneHotEncoder, StringIndexer\n",
        "\n",
        "def one_hot_encode(df, feature):\n",
        "  df = df.withColumn(feature, when(F.col(feature) == '', None).otherwise(F.col(feature)))\n",
        "\n",
        "  # Map strings to numbers with string indexer\n",
        "  string_indexer = StringIndexer(inputCol=feature, outputCol=f'{feature}_index')\n",
        "  indexed_df = string_indexer.fit(df).transform(df)\n",
        "\n",
        "  # Onehot encode indexed values\n",
        "  encoder = OneHotEncoder(inputCol=f'{feature}_index', outputCol=f'{feature}_vec')\n",
        "  encoded_df = encoder.fit(indexed_df).transform(indexed_df)\n",
        "\n",
        "  extra_column = (feature, f\"{feature}_index\")\n",
        "  encoded_df = encoded_df.drop(*extra_column)\n",
        "\n",
        "  return encoded_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "294w-IlD4AmL"
      },
      "outputs": [],
      "source": [
        "# df = one_hot_encode(df, 'username')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kDWDzOdc4a9y"
      },
      "outputs": [],
      "source": [
        "# df = one_hot_encode(df, 'to')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ajS30EtvI0TQ"
      },
      "outputs": [],
      "source": [
        "# df.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "blFkzr6-AIEE"
      },
      "source": [
        "## Processing Twitter Text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dhj_mbGfAOX1",
        "outputId": "072dcd47-16ac-44a1-9868-1d57a930c6dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---------------+---+----------------------------------------------------------------------------------------------------------------------------------------------+-------------------+----------+---------------+---------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|username       |to |text                                                                                                                                          |date               |engagement|number_hashtags|number_mentions|words                                                                                                                                                                     |\n",
            "+---------------+---+----------------------------------------------------------------------------------------------------------------------------------------------+-------------------+----------+---------------+---------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|SneakerShouts  |   |\"STEAL Over OFF free shipping on the Nike Air Huarache OG \"\"Persian Violet\"\" BUY HERE http bit ly wsRZdW pic twitter com f nIazjbmT\"          |2019-04-01 00:00:00|26        |0              |0              |[\"steal, over, off, free, shipping, on, the, nike, air, huarache, og, \"\"persian, violet\"\", buy, here, http, bit, ly, wsrzdw, pic, twitter, com, f, niazjbmt\"]             |\n",
            "|Ebay_Birmingham|   |Check out Nike Dry Fit Shorts Women's Tempo Neon Pink Yellow Lined Swoosh Active Sz M Nike https ebay us WY wrA via eBay ebay poshmark mercari|2019-04-01 00:00:00|0         |5              |1              |[check, out, nike, dry, fit, shorts, women's, tempo, neon, pink, yellow, lined, swoosh, active, sz, m, nike, https, ebay, us, wy, wra, via, ebay, ebay, poshmark, mercari]|\n",
            "|SneakerNews    |   |\"The Nike Air Max \"\"Seoul\"\" will release via Nike SNKRS on April th https snkrne ws uw i E pic twitter com MPcKBT lz\"                         |2019-04-01 00:00:00|119       |0              |0              |[\"the, nike, air, max, \"\"seoul\"\", will, release, via, nike, snkrs, on, april, th, https, snkrne, ws, uw, i, e, pic, twitter, com, mpckbt, lz\"]                            |\n",
            "|titoloshop     |   |Nike Air Vapormax Flyknit Atmosphere Grey Reflect Silver RELEASE Monday st April AM CET http bit ly HXA OU pic twitter com kRvrW rXDw         |2019-04-01 00:00:00|0         |0              |0              |[nike, air, vapormax, flyknit, atmosphere, grey, reflect, silver, release, monday, st, april, am, cet, http, bit, ly, hxa, ou, pic, twitter, com, krvrw, rxdw]            |\n",
            "+---------------+---+----------------------------------------------------------------------------------------------------------------------------------------------+-------------------+----------+---------------+---------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "only showing top 4 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql.functions import regexp_replace\n",
        "from pyspark.ml.feature import Tokenizer\n",
        "\n",
        "# Remove punctuation (REGEX provided) and numbers\n",
        "wrangled = df.withColumn('text', regexp_replace(df.text, '[_():;,.@#\\/!%\\+?\\\\-]', ' '))\n",
        "wrangled = wrangled.withColumn('text', regexp_replace(wrangled.text, '[0-9]', ' '))\n",
        "\n",
        "# Merge multiple spaces\n",
        "wrangled = wrangled.withColumn('text', regexp_replace(wrangled.text, ' +', ' '))\n",
        "\n",
        "# Split the text into words\n",
        "wrangled = Tokenizer(inputCol='text', outputCol='words').transform(wrangled)\n",
        "\n",
        "wrangled.show(4, truncate=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ftcH_oS2ozD",
        "outputId": "be7d1b45-71b0-40e0-e8ac-68f99c330149"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|terms                                                                                                                                                                |features                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|[\"steal, free, shipping, nike, air, huarache, og, \"\"persian, violet\"\", buy, http, bit, ly, wsrzdw, pic, twitter, com, f, niazjbmt\"]                                  |(1024,[120,193,221,329,330,488,531,549,595,598,638,671,768,789,830,915,950,979,996],[1.8548635531406916,3.4263211514376684,2.3388469034105257,1.7377334665793225,3.576042825398918,1.0266078608494207,1.5847334870686396,2.4250641969813755,3.851605480514457,0.6604404580880586,4.583204153385793,3.717044205279833,3.0257883902962495,4.692022239879393,3.112807801705332,5.438689755800993,5.524148861279697,4.912719434612777,0.18262619183558798])                                                                                         |\n",
            "|[check, nike, dry, fit, shorts, women's, tempo, neon, pink, yellow, lined, swoosh, active, sz, m, nike, https, ebay, us, wy, wra, via, ebay, ebay, poshmark, mercari]|(1024,[5,33,102,142,169,190,217,253,255,256,282,286,429,481,568,612,674,723,892,993,996],[3.4852397095520624,3.9289668694740367,9.480982418106029,2.6028340233936036,3.941846574845976,7.453056186831011,3.2508175706538003,2.3386877810169895,5.1849083395087865,5.66367887762125,3.2125863091843048,1.0849018191379904,4.840237455885431,3.465118159654279,4.171788240943575,2.9306494844640913,4.834685761175297,5.313346366887139,7.714225225352532,2.523123987815006,0.36525238367117596])                                                 |\n",
            "|[\"the, nike, air, max, \"\"seoul\"\", release, via, nike, snkrs, april, th, https, snkrne, ws, uw, e, pic, twitter, com, mpckbt, lz\"]                                    |(1024,[1,27,83,104,120,141,174,228,286,488,531,598,696,718,782,854,923,993,996],[4.981354985909638,5.233839557349374,4.575418761081812,2.8385908027674067,1.8548635531406916,4.157983895027424,3.855479680453638,3.1639974770647044,1.0849018191379904,1.0266078608494207,3.169466974137279,0.6604404580880586,3.664536190636609,5.026512344544058,3.086481333166425,2.695214322686365,2.6210941756483077,2.523123987815006,0.36525238367117596])                                                                                               |\n",
            "|[nike, air, vapormax, flyknit, atmosphere, grey, reflect, silver, release, monday, st, april, cet, http, bit, ly, hxa, ou, pic, twitter, com, krvrw, rxdw]           |(1024,[120,208,217,221,228,317,327,329,478,488,531,536,549,565,589,598,619,701,727,758,851,923,996],[1.8548635531406916,5.203208972252721,3.2508175706538003,2.3388469034105257,3.1639974770647044,4.636599433800818,4.872823647022248,1.7377334665793225,3.9986658401369786,1.0266078608494207,1.5847334870686396,5.02771689444621,2.4250641969813755,3.598617589314595,4.303413067241718,0.6604404580880586,4.434039848065577,4.072594922006285,3.978769838475758,4.006386646119998,4.498108076541884,2.6210941756483077,0.18262619183558798])|\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "only showing top 4 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.ml.feature import StopWordsRemover, HashingTF, IDF\n",
        "\n",
        "# Remove stop words.\n",
        "wrangled = StopWordsRemover(inputCol='words', outputCol='terms')\\\n",
        "      .transform(wrangled)\n",
        "\n",
        "# Apply the hashing trick\n",
        "wrangled = HashingTF(inputCol='terms', outputCol='hash', numFeatures=1024)\\\n",
        "      .transform(wrangled)\n",
        "\n",
        "# Convert hashed symbols to TF-IDF\n",
        "tf_idf = IDF(inputCol='hash', outputCol='features')\\\n",
        "      .fit(wrangled).transform(wrangled)\n",
        "      \n",
        "tf_idf.select('terms', 'features').show(4, truncate=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fu4Re8LZ8orj",
        "outputId": "4e745edb-1dbf-479b-f9da-54663ccacd72"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---------------+---+----------------------------------------------------------------------------------------------------------------------------------------------+-------------------+----------+---------------+---------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|username       |to |text                                                                                                                                          |date               |engagement|number_hashtags|number_mentions|words                                                                                                                                                                     |terms                                                                                                                                                                |hash                                                                                                                                                                                              |features                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |\n",
            "+---------------+---+----------------------------------------------------------------------------------------------------------------------------------------------+-------------------+----------+---------------+---------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|SneakerShouts  |   |\"STEAL Over OFF free shipping on the Nike Air Huarache OG \"\"Persian Violet\"\" BUY HERE http bit ly wsRZdW pic twitter com f nIazjbmT\"          |2019-04-01 00:00:00|26        |0              |0              |[\"steal, over, off, free, shipping, on, the, nike, air, huarache, og, \"\"persian, violet\"\", buy, here, http, bit, ly, wsrzdw, pic, twitter, com, f, niazjbmt\"]             |[\"steal, free, shipping, nike, air, huarache, og, \"\"persian, violet\"\", buy, http, bit, ly, wsrzdw, pic, twitter, com, f, niazjbmt\"]                                  |(1024,[120,193,221,329,330,488,531,549,595,598,638,671,768,789,830,915,950,979,996],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])                                |(1024,[120,193,221,329,330,488,531,549,595,598,638,671,768,789,830,915,950,979,996],[1.8548635531406916,3.4263211514376684,2.3388469034105257,1.7377334665793225,3.576042825398918,1.0266078608494207,1.5847334870686396,2.4250641969813755,3.851605480514457,0.6604404580880586,4.583204153385793,3.717044205279833,3.0257883902962495,4.692022239879393,3.112807801705332,5.438689755800993,5.524148861279697,4.912719434612777,0.18262619183558798])                                                                                         |\n",
            "|Ebay_Birmingham|   |Check out Nike Dry Fit Shorts Women's Tempo Neon Pink Yellow Lined Swoosh Active Sz M Nike https ebay us WY wrA via eBay ebay poshmark mercari|2019-04-01 00:00:00|0         |5              |1              |[check, out, nike, dry, fit, shorts, women's, tempo, neon, pink, yellow, lined, swoosh, active, sz, m, nike, https, ebay, us, wy, wra, via, ebay, ebay, poshmark, mercari]|[check, nike, dry, fit, shorts, women's, tempo, neon, pink, yellow, lined, swoosh, active, sz, m, nike, https, ebay, us, wy, wra, via, ebay, ebay, poshmark, mercari]|(1024,[5,33,102,142,169,190,217,253,255,256,282,286,429,481,568,612,674,723,892,993,996],[1.0,1.0,2.0,1.0,1.0,3.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,2.0,1.0,2.0])                   |(1024,[5,33,102,142,169,190,217,253,255,256,282,286,429,481,568,612,674,723,892,993,996],[3.4852397095520624,3.9289668694740367,9.480982418106029,2.6028340233936036,3.941846574845976,7.453056186831011,3.2508175706538003,2.3386877810169895,5.1849083395087865,5.66367887762125,3.2125863091843048,1.0849018191379904,4.840237455885431,3.465118159654279,4.171788240943575,2.9306494844640913,4.834685761175297,5.313346366887139,7.714225225352532,2.523123987815006,0.36525238367117596])                                                 |\n",
            "|SneakerNews    |   |\"The Nike Air Max \"\"Seoul\"\" will release via Nike SNKRS on April th https snkrne ws uw i E pic twitter com MPcKBT lz\"                         |2019-04-01 00:00:00|119       |0              |0              |[\"the, nike, air, max, \"\"seoul\"\", will, release, via, nike, snkrs, on, april, th, https, snkrne, ws, uw, i, e, pic, twitter, com, mpckbt, lz\"]                            |[\"the, nike, air, max, \"\"seoul\"\", release, via, nike, snkrs, april, th, https, snkrne, ws, uw, e, pic, twitter, com, mpckbt, lz\"]                                    |(1024,[1,27,83,104,120,141,174,228,286,488,531,598,696,718,782,854,923,993,996],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,2.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,2.0])                                    |(1024,[1,27,83,104,120,141,174,228,286,488,531,598,696,718,782,854,923,993,996],[4.981354985909638,5.233839557349374,4.575418761081812,2.8385908027674067,1.8548635531406916,4.157983895027424,3.855479680453638,3.1639974770647044,1.0849018191379904,1.0266078608494207,3.169466974137279,0.6604404580880586,3.664536190636609,5.026512344544058,3.086481333166425,2.695214322686365,2.6210941756483077,2.523123987815006,0.36525238367117596])                                                                                               |\n",
            "|titoloshop     |   |Nike Air Vapormax Flyknit Atmosphere Grey Reflect Silver RELEASE Monday st April AM CET http bit ly HXA OU pic twitter com kRvrW rXDw         |2019-04-01 00:00:00|0         |0              |0              |[nike, air, vapormax, flyknit, atmosphere, grey, reflect, silver, release, monday, st, april, am, cet, http, bit, ly, hxa, ou, pic, twitter, com, krvrw, rxdw]            |[nike, air, vapormax, flyknit, atmosphere, grey, reflect, silver, release, monday, st, april, cet, http, bit, ly, hxa, ou, pic, twitter, com, krvrw, rxdw]           |(1024,[120,208,217,221,228,317,327,329,478,488,531,536,549,565,589,598,619,701,727,758,851,923,996],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])|(1024,[120,208,217,221,228,317,327,329,478,488,531,536,549,565,589,598,619,701,727,758,851,923,996],[1.8548635531406916,5.203208972252721,3.2508175706538003,2.3388469034105257,3.1639974770647044,4.636599433800818,4.872823647022248,1.7377334665793225,3.9986658401369786,1.0266078608494207,1.5847334870686396,5.02771689444621,2.4250641969813755,3.598617589314595,4.303413067241718,0.6604404580880586,4.434039848065577,4.072594922006285,3.978769838475758,4.006386646119998,4.498108076541884,2.6210941756483077,0.18262619183558798])|\n",
            "+---------------+---+----------------------------------------------------------------------------------------------------------------------------------------------+-------------------+----------+---------------+---------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "only showing top 4 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "tf_idf.show(4, truncate=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4FYB0XI31BlW"
      },
      "outputs": [],
      "source": [
        "# Convert text to embedding\n",
        "# Convert hashtags to one-hot encoding\n",
        "# Convert username to one-hot encoding\n",
        "# Convert \"to\" to one-hot encoding\n",
        "# Convert date"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lt4j72MwiJ9u"
      },
      "source": [
        "# Model Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wQKXAdVrE2Q2"
      },
      "outputs": [],
      "source": [
        "trainable_tf_id = tf_idf.select('username', 'number_hashtags', 'number_mentions', 'features', 'engagement')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8f_SenI8trJe",
        "outputId": "ffbfd85b-eda1-4df3-eae9-0e9bfb42a3bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---------------+---------------+---------------+--------------------+----------+\n",
            "|       username|number_hashtags|number_mentions|            features|engagement|\n",
            "+---------------+---------------+---------------+--------------------+----------+\n",
            "|  SneakerShouts|              0|              0|(1024,[120,193,22...|        26|\n",
            "|Ebay_Birmingham|              5|              1|(1024,[5,33,102,1...|         0|\n",
            "|    SneakerNews|              0|              0|(1024,[1,27,83,10...|       119|\n",
            "|     titoloshop|              0|              0|(1024,[120,208,21...|         0|\n",
            "|   Taniabanks24|              0|              1|(1024,[18,49,179,...|         2|\n",
            "|         bodega|              3|              0|(1024,[140,171,22...|        11|\n",
            "|   mitasneakers|              0|              0|(1024,[63,120,145...|         3|\n",
            "|  CentervilleCF|              0|              0|(1024,[192,286,34...|         2|\n",
            "| BBNSportsKSCDJ|              0|              0|(1024,[265,355,68...|         0|\n",
            "|    SoleInsider|              0|              0|(1024,[61,120,286...|         0|\n",
            "|     WendyCerne|              0|              1|(1024,[328,340,36...|         1|\n",
            "|      robseize_|              2|              0|(1024,[72,165,277...|         0|\n",
            "| nexgenscouting|              0|              4|(1024,[43,119,186...|        10|\n",
            "|     snkr_twitr|              1|              0|(1024,[84,100,120...|        13|\n",
            "|  JustMightLook|              0|              0|(1024,[58,104,120...|         0|\n",
            "|  JustMightLook|              0|              0|(1024,[58,104,120...|         0|\n",
            "|  JustMightLook|              0|              0|(1024,[11,58,104,...|         0|\n",
            "|    breezeavery|              0|              0|(1024,[16,133,165...|       117|\n",
            "|     StockXLive|              1|              0|(1024,[184,250,28...|         4|\n",
            "|   MrsSimone2u_|              0|              0|(1024,[87,100,120...|         0|\n",
            "+---------------+---------------+---------------+--------------------+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "trainable_tf_id.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "qS94JEpciA2b",
        "outputId": "024cc227-2378-4417-b66b-689e4c092f4e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---------------+----------+-----+\n",
            "|       username|engagement|count|\n",
            "+---------------+----------+-----+\n",
            "|    ClosEMSmile|        22|    1|\n",
            "|       BluThief|         0|    1|\n",
            "|  ChrisShaw20KC|         0|    1|\n",
            "| kutsushita___3|         9|    1|\n",
            "|Hg1AWnAVVZcbSGq|         1|    1|\n",
            "|      juliush23|         1|    1|\n",
            "| lionslogistics|         2|    1|\n",
            "|superyeezyboost|         1|    1|\n",
            "| KaylieAbelaArt|         0|    1|\n",
            "|Shop_FINAL_FOUR|         1|    1|\n",
            "|     ayeeeeeric|         2|    1|\n",
            "|       Griouard|         1|    1|\n",
            "|  IsaiahDavid96|         0|    1|\n",
            "|     snoozie223|         2|    1|\n",
            "|      MrTamPham|         0|    1|\n",
            "|DlameBuhlebethu|         2|    1|\n",
            "|    Inkfacefahz|         4|    1|\n",
            "|     marlatroll|         0|    1|\n",
            "|      FSURising|         0|    1|\n",
            "|  SoleTalkDaily|         0|    6|\n",
            "+---------------+----------+-----+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#**Just for testing purpose **\n",
        "\n",
        "# Import LinearRegression\n",
        "from pyspark.ml.regression import LinearRegression\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "tf_train, tf_test = trainable_tf_id.randomSplit([0.999, 0.001], seed=13)\n",
        "\n",
        "# Fit a Logistic Regression model to the training data\n",
        "linear = LinearRegression(labelCol='engagement').fit(tf_test)\n",
        "\n",
        "# Make predictions on the testing data\n",
        "prediction = linear.transform(tf_test)\n",
        "#y_pred = LinearRegression.predict(tf_test)\n",
        "# Create a confusion matrix, comparing predictions to known labels\n",
        "prediction.groupBy('username', 'engagement').count().show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Logistic algorithm\n"
      ],
      "metadata": {
        "id": "w2wy4Q6iIvTX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "val seed = 5000\n",
        "val Array(tf_train, tf_test) = trainable_tf_id.randomSplit(Array(0.6, 0.4), seed)\n",
        "\n",
        "// train logistic regression model with training data set\n",
        "val logisticRegression = new LogisticRegression()\n",
        "  .setMaxIter(100)\n",
        "  .setRegParam(0.02)\n",
        "  .setElasticNetParam(0.8)\n",
        "val logisticRegressionModel = logisticRegression.fit(tf_train)\n",
        "\n",
        "// run model with test data set to get predictions\n",
        "// this will add new columns rawPrediction, probability and prediction\n",
        "val predictionDf = logisticRegressionModel.transform(tf_test)\n",
        "predictionDf.show(10)"
      ],
      "metadata": {
        "id": "CFGS9pNIM9yW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate model with area under ROC\n",
        "val evaluator = new BinaryClassificationEvaluator()\n",
        "  .setLabelCol(\"engagement\")\n",
        "  .setRawPredictionCol(\"username\")\n",
        "  .setMetricName(\"areaUnderROC\")\n",
        "\n",
        "# measure the accuracy\n",
        "val accuracy = evaluator.evaluate(predictionDf)\n",
        "println(accuracy)\n",
        "\n"
      ],
      "metadata": {
        "id": "J6WyXkphM9vk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "JrtYNpyOM9sj"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Predicting_Number_of_Engagements_for_a_Tweet.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}